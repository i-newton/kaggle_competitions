{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and analyze data + some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/8d/783679697bdf1585dc96acfe7c8538d6fab33ad80e827cadb7b413e61da6/lightgbm-2.1.2-py2.py3-none-manylinux1_x86_64.whl (730kB)\n",
      "\u001b[K    100% |████████████████████████████████| 737kB 4.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/kairat/PycharmProjects/kaggle_competitions/venv/lib/python3.5/site-packages (from lightgbm) (1.1.0)\n",
      "Collecting scikit-learn (from lightgbm)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/53/8c9c950a3cfaec16069df196c0b76ab05b3d1f0527f6bb97a30f4dda5240/scikit_learn-0.19.1-cp35-cp35m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/kairat/PycharmProjects/kaggle_competitions/venv/lib/python3.5/site-packages (from lightgbm) (1.14.3)\n",
      "Installing collected packages: scikit-learn, lightgbm\n",
      "Successfully installed lightgbm-2.1.2 scikit-learn-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "y = train_df[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), np.sort(train_df['target'].values))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Target', fontsize=12)\n",
    "plt.title(\"Target Distribution\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kairat/PycharmProjects/kaggle_competitions/venv/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot( np.log1p(train_df[\"target\"].values), bins=50, kde=False)\n",
    "plt.xlabel('Target', fontsize=12)\n",
    "plt.title(\"Log of Target Histogram\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = train_df.nunique().reset_index()\n",
    "unique_df.columns = [\"col_name\", \"unique_count\"]\n",
    "constant_df = unique_df[unique_df[\"unique_count\"]==1]\n",
    "constant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34ceb0081', '8d57e2749', '168b3e5bc', 'a765da8bc', 'acc5b709d']\n"
     ]
    }
   ],
   "source": [
    "def duplicate_columns(frame):\n",
    "    groups = frame.columns.to_series().groupby(frame.dtypes).groups\n",
    "    dups = []\n",
    "\n",
    "    for t, v in groups.items():\n",
    "\n",
    "        cs = frame[v].columns\n",
    "        vs = frame[v]\n",
    "        lcs = len(cs)\n",
    "\n",
    "        for i in range(lcs):\n",
    "            ia = vs.iloc[:,i].values\n",
    "            for j in range(i+1, lcs):\n",
    "                ja = vs.iloc[:,j].values\n",
    "                if np.array_equal(ia, ja):\n",
    "                    dups.append(cs[i])\n",
    "                    break\n",
    "\n",
    "    return dups\n",
    "\n",
    "colsToRemove = ['34ceb0081', '8d57e2749', '168b3e5bc', 'a765da8bc', 'acc5b709d']\n",
    "print(colsToRemove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = constant_df.col_name.tolist()\n",
    "train_X = train_df.drop(labels=drop_list+colsToRemove+[\"target\",\"ID\"], axis = 1)\n",
    "test_X = test_df.drop(labels=drop_list+colsToRemove+[\"ID\"], axis = 1)\n",
    "train_y = np.log1p(train_df[\"target\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.01,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=200, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.44231\n",
      "[400]\tvalid_0's rmse: 1.42178\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's rmse: 1.42093\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.44249\n",
      "[400]\tvalid_0's rmse: 1.40968\n",
      "[600]\tvalid_0's rmse: 1.40662\n",
      "Early stopping, best iteration is:\n",
      "[532]\tvalid_0's rmse: 1.40543\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.44369\n",
      "[400]\tvalid_0's rmse: 1.41905\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's rmse: 1.41808\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.49096\n",
      "[400]\tvalid_0's rmse: 1.45485\n",
      "[600]\tvalid_0's rmse: 1.44857\n",
      "[800]\tvalid_0's rmse: 1.44774\n",
      "[1000]\tvalid_0's rmse: 1.44622\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[982]\tvalid_0's rmse: 1.44611\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's rmse: 1.48257\n",
      "[400]\tvalid_0's rmse: 1.4627\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's rmse: 1.46182\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "kf = model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=2017)\n",
    "pred_test_full = 0\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n",
    "    pred_test_full += pred_test\n",
    "pred_test_full /= n_splits\n",
    "pred_test_full = np.expm1(pred_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a submission file #\n",
    "sub_df = pd.DataFrame({\"ID\":test_df[\"ID\"].values})\n",
    "sub_df[\"target\"] = pred_test_full\n",
    "sub_df.to_csv(\"/tmp/baseline_lgb_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1720684.28787874, 1757135.74636376, 1569253.87933019, ...,\n",
       "        849069.08530653,  715043.97673542, 1972984.68715116])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_norm = scaler.fit_transform(train_df)\n",
    "test_norm = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "reduced_train = pca.fit_transform(train_df)\n",
    "reduced_test = pca.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 1221)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py:314: RuntimeWarning: invalid value encountered in log\n",
      "  return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n",
      "/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py:314: RuntimeWarning: invalid value encountered in log\n",
      "  return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n",
      "/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py:314: RuntimeWarning: invalid value encountered in log\n",
      "  return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f40e4ea78a0, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/snake/PycharmProjects/kaggle_competitions/...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/snake/PycharmProjects/kaggle_competitions/...lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/snake/.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f40e4ea78a0, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/snake/PycharmProjects/kaggle_competitions/...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/snake/PycharmProjects/kaggle_competitions/...lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/snake/.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    340             raise RuntimeError('Event loop is running.')\n    341         self._set_coroutine_wrapper(self._debug)\n    342         self._thread_id = threading.get_ident()\n    343         try:\n    344             while True:\n--> 345                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    346                 if self._stopping:\n    347                     break\n    348         finally:\n    349             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1307                         logger.warning('Executing %s took %.3f seconds',\n   1308                                        _format_handle(handle), dt)\n   1309                 finally:\n   1310                     self._current_handle = None\n   1311             else:\n-> 1312                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(13, 1)>>\n   1313         handle = None  # Needed to break cycles when an exception occurs.\n   1314 \n   1315     def _set_coroutine_wrapper(self, enabled):\n   1316         try:\n\n...........................................................................\n/usr/lib/python3.5/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(13, 1)>)\n    120             self._callback = None\n    121             self._args = None\n    122 \n    123     def _run(self):\n    124         try:\n--> 125             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (13, 1)\n    126         except Exception as exc:\n    127             cb = _format_callback_source(self._callback, self._args)\n    128             msg = 'Exception in callback {}'.format(cb)\n    129             context = {\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=13, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'cbf242742573403d9bdc524a8fcc1ae4']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'cbf242742573403d9bdc524a8fcc1ae4'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-124-d14af685002f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>\n        result = <ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>, result=<ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>\n        self.user_global_ns = {'C': [2, 1, 0.5, 0.1], 'In': ['', 'import numpy as np\\nimport pandas as pd', 'train_df = pd.read_csv(\"../data/train.csv\")\\ntest_df = pd.read_csv(\"../data/test.csv\")', 'train_df.head()', 'train_df.shape', 'test_df.shape', 'test_df.head()', 'train_df = pd.read_csv(\"../data/train.csv\", inde...= pd.read_csv(\"../data/test.csv\", index_col=\"ID\")', 'test_df.head()', 'train_df.head()', 'y = train_df[:]', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1. inplace=True)', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1, inplace=True)', 'train_df.head()', 'print(train_df.shape)\\ntrain_df.head()', 'y', 'y.nunique()', 'train_df[0]', 'train_df.values()[0]', 'train_df.values[0]', ...], 'Out': {3:           ID      target  48df886f9  0deb4b6a8  ...          0          0  \n\n[5 rows x 4993 columns], 4: (4459, 4993), 5: (49342, 4992), 6:           ID  48df886f9  0deb4b6a8  34b15f335  a...        0.0        0.0  \n\n[5 rows x 4992 columns], 8:            48df886f9  0deb4b6a8  34b15f335  a8cb...        0.0        0.0  \n\n[5 rows x 4991 columns], 9:                target  48df886f9  0deb4b6a8  34b...          0          0  \n\n[5 rows x 4992 columns], 13:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 14:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 15: ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, 16: 1413, ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, 'SVR': <class 'sklearn.svm.classes.SVR'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([12897.35154522, 14710.70136138, 11476.602...  9269.30800624, 11362.80565186,  7221.68147366]), '_100': array([[-0.03764565, -0.02163947, -0.04688961, .... -0.07234203,\n        -0.05636327, -0.12585201]]), '_102':            48df886f9  0deb4b6a8     34b15f335  a...f6f       0.000000  \n\n[49342 rows x 4991 columns], ...}\n        self.user_ns = {'C': [2, 1, 0.5, 0.1], 'In': ['', 'import numpy as np\\nimport pandas as pd', 'train_df = pd.read_csv(\"../data/train.csv\")\\ntest_df = pd.read_csv(\"../data/test.csv\")', 'train_df.head()', 'train_df.shape', 'test_df.shape', 'test_df.head()', 'train_df = pd.read_csv(\"../data/train.csv\", inde...= pd.read_csv(\"../data/test.csv\", index_col=\"ID\")', 'test_df.head()', 'train_df.head()', 'y = train_df[:]', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1. inplace=True)', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1, inplace=True)', 'train_df.head()', 'print(train_df.shape)\\ntrain_df.head()', 'y', 'y.nunique()', 'train_df[0]', 'train_df.values()[0]', 'train_df.values[0]', ...], 'Out': {3:           ID      target  48df886f9  0deb4b6a8  ...          0          0  \n\n[5 rows x 4993 columns], 4: (4459, 4993), 5: (49342, 4992), 6:           ID  48df886f9  0deb4b6a8  34b15f335  a...        0.0        0.0  \n\n[5 rows x 4992 columns], 8:            48df886f9  0deb4b6a8  34b15f335  a8cb...        0.0        0.0  \n\n[5 rows x 4991 columns], 9:                target  48df886f9  0deb4b6a8  34b...          0          0  \n\n[5 rows x 4992 columns], 13:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 14:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 15: ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, 16: 1413, ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, 'SVR': <class 'sklearn.svm.classes.SVR'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([12897.35154522, 14710.70136138, 11476.602...  9269.30800624, 11362.80565186,  7221.68147366]), '_100': array([[-0.03764565, -0.02163947, -0.04688961, .... -0.07234203,\n        -0.05636327, -0.12585201]]), '_102':            48df886f9  0deb4b6a8     34b15f335  a...f6f       0.000000  \n\n[49342 rows x 4991 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/santander/src/<ipython-input-124-d14af685002f> in <module>()\n      1 from sklearn.linear_model import Ridge\n      2 ridge = Ridge(random_state=17)\n----> 3 scores = cross_val_score(ridge, reduced_train, y, n_jobs = -1, verbose=1,  scoring=\"neg_mean_squared_log_error\")\n      4 print(np.mean(np.sqrt(-scores)))\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, groups=None, scoring='neg_mean_squared_log_error', cv=None, n_jobs=-1, verbose=1, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, groups=None, scoring={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, cv=KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=1, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]])\n        y = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jun 23 18:26:59 2018\nPID: 5759Python 3.5.2: /home/snake/PycharmProjects/kaggle_competitions/.venv/bin/python3\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, train=array([1487, 1488, 1489, ..., 4456, 4457, 4458]), test=array([   0,    1,    2, ..., 1484, 1485, 1486]), verbose=1, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _multimetric_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorers={'score': make_scorer(mean_squared_log_error, greater_is_better=False)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(mean_squared_log_error, greater_is_better=False)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(mean_squared_log_error, greater_is_better=False), estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_true=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_log_error(y_true=array([[38000000.],\n       [  600000.],\n       [...00000.],\n       [ 6000000.],\n       [  922000.]]), y_pred=array([[  9008546.15738128],\n       [  6759237.4... 6826125.46616534],\n       [-25818253.49610107]]), sample_weight=None, multioutput='uniform_average')\n    310     if not (y_true >= 0).all() and not (y_pred >= 0).all():\n    311         raise ValueError(\"Mean Squared Logarithmic Error cannot be used when \"\n    312                          \"targets contain negative values.\")\n    313 \n    314     return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n--> 315                               sample_weight, multioutput)\n        sample_weight = None\n        multioutput = 'uniform_average'\n    316 \n    317 \n    318 def median_absolute_error(y_true, y_pred):\n    319     \"\"\"Median absolute error regression loss\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_error(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), sample_weight=None, multioutput='uniform_average')\n    233     ... # doctest: +ELLIPSIS\n    234     0.824...\n    235 \n    236     \"\"\"\n    237     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 238         y_true, y_pred, multioutput)\n        y_true = array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]])\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n        multioutput = 'uniform_average'\n    239     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n    240                                weights=sample_weight)\n    241     if isinstance(multioutput, string_types):\n    242         if multioutput == 'raw_values':\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), multioutput='uniform_average')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in check_array(array=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 488, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\", line 553, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py\", line 108, in __call__\n    **self._kwargs)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py\", line 315, in mean_squared_log_error\n    sample_weight, multioutput)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py\", line 238, in mean_squared_error\n    y_true, y_pred, multioutput)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py\", line 77, in _check_reg_targets\n    y_pred = check_array(y_pred, ensure_2d=False)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py\", line 453, in check_array\n    _assert_all_finite(array)\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py\", line 44, in _assert_all_finite\n    \" or a value too large for %r.\" % X.dtype)\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jun 23 18:26:59 2018\nPID: 5759Python 3.5.2: /home/snake/PycharmProjects/kaggle_competitions/.venv/bin/python3\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, train=array([1487, 1488, 1489, ..., 4456, 4457, 4458]), test=array([   0,    1,    2, ..., 1484, 1485, 1486]), verbose=1, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _multimetric_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorers={'score': make_scorer(mean_squared_log_error, greater_is_better=False)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(mean_squared_log_error, greater_is_better=False)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(mean_squared_log_error, greater_is_better=False), estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_true=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_log_error(y_true=array([[38000000.],\n       [  600000.],\n       [...00000.],\n       [ 6000000.],\n       [  922000.]]), y_pred=array([[  9008546.15738128],\n       [  6759237.4... 6826125.46616534],\n       [-25818253.49610107]]), sample_weight=None, multioutput='uniform_average')\n    310     if not (y_true >= 0).all() and not (y_pred >= 0).all():\n    311         raise ValueError(\"Mean Squared Logarithmic Error cannot be used when \"\n    312                          \"targets contain negative values.\")\n    313 \n    314     return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n--> 315                               sample_weight, multioutput)\n        sample_weight = None\n        multioutput = 'uniform_average'\n    316 \n    317 \n    318 def median_absolute_error(y_true, y_pred):\n    319     \"\"\"Median absolute error regression loss\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_error(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), sample_weight=None, multioutput='uniform_average')\n    233     ... # doctest: +ELLIPSIS\n    234     0.824...\n    235 \n    236     \"\"\"\n    237     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 238         y_true, y_pred, multioutput)\n        y_true = array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]])\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n        multioutput = 'uniform_average'\n    239     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n    240                                weights=sample_weight)\n    241     if isinstance(multioutput, string_types):\n    242         if multioutput == 'raw_values':\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), multioutput='uniform_average')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in check_array(array=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jun 23 18:26:59 2018\nPID: 5759Python 3.5.2: /home/snake/PycharmProjects/kaggle_competitions/.venv/bin/python3\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, train=array([1487, 1488, 1489, ..., 4456, 4457, 4458]), test=array([   0,    1,    2, ..., 1484, 1485, 1486]), verbose=1, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _multimetric_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorers={'score': make_scorer(mean_squared_log_error, greater_is_better=False)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(mean_squared_log_error, greater_is_better=False)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(mean_squared_log_error, greater_is_better=False), estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_true=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_log_error(y_true=array([[38000000.],\n       [  600000.],\n       [...00000.],\n       [ 6000000.],\n       [  922000.]]), y_pred=array([[  9008546.15738128],\n       [  6759237.4... 6826125.46616534],\n       [-25818253.49610107]]), sample_weight=None, multioutput='uniform_average')\n    310     if not (y_true >= 0).all() and not (y_pred >= 0).all():\n    311         raise ValueError(\"Mean Squared Logarithmic Error cannot be used when \"\n    312                          \"targets contain negative values.\")\n    313 \n    314     return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n--> 315                               sample_weight, multioutput)\n        sample_weight = None\n        multioutput = 'uniform_average'\n    316 \n    317 \n    318 def median_absolute_error(y_true, y_pred):\n    319     \"\"\"Median absolute error regression loss\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_error(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), sample_weight=None, multioutput='uniform_average')\n    233     ... # doctest: +ELLIPSIS\n    234     0.824...\n    235 \n    236     \"\"\"\n    237     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 238         y_true, y_pred, multioutput)\n        y_true = array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]])\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n        multioutput = 'uniform_average'\n    239     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n    240                                weights=sample_weight)\n    241     if isinstance(multioutput, string_types):\n    242         if multioutput == 'raw_values':\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), multioutput='uniform_average')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in check_array(array=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-d14af685002f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_log_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f40e4ea78a0, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/snake/PycharmProjects/kaggle_competitions/...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/snake/PycharmProjects/kaggle_competitions/...lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/snake/.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f40e4ea78a0, file \"/...3.5/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/snake/PycharmProjects/kaggle_competitions/...ges/__pycache__/ipykernel_launcher.cpython-35.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/snake/PycharmProjects/kaggle_competitions/...lib/python3.5/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.5/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/snake/.../python3.5/site-packages/ipykernel/kernelapp.py'>, 'sys': <module 'sys' (built-in)>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    340             raise RuntimeError('Event loop is running.')\n    341         self._set_coroutine_wrapper(self._debug)\n    342         self._thread_id = threading.get_ident()\n    343         try:\n    344             while True:\n--> 345                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    346                 if self._stopping:\n    347                     break\n    348         finally:\n    349             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.5/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1307                         logger.warning('Executing %s took %.3f seconds',\n   1308                                        _format_handle(handle), dt)\n   1309                 finally:\n   1310                     self._current_handle = None\n   1311             else:\n-> 1312                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(13, 1)>>\n   1313         handle = None  # Needed to break cycles when an exception occurs.\n   1314 \n   1315     def _set_coroutine_wrapper(self, enabled):\n   1316         try:\n\n...........................................................................\n/usr/lib/python3.5/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(13, 1)>)\n    120             self._callback = None\n    121             self._args = None\n    122 \n    123     def _run(self):\n    124         try:\n--> 125             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (13, 1)\n    126         except Exception as exc:\n    127             cb = _format_callback_source(self._callback, self._args)\n    128             msg = 'Exception in callback {}'.format(cb)\n    129             context = {\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=13, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'cbf242742573403d9bdc524a8fcc1ae4']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'cbf242742573403d9bdc524a8fcc1ae4'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 23, 14, 26, 57, 493746, tzinfo=tzutc()), 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'session': 'cbf242742573403d9bdc524a8fcc1ae4', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '36c8e0393eb24bc18bb0270333874192', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.linear_model import Ridge\\nridge = R...ared_log_error\")\\nprint(np.mean(np.sqrt(-scores)))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-124-d14af685002f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>\n        result = <ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>, result=<ExecutionResult object at 7f409fa7b9b0, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f40a0c0a4b0, file \"<ipython-input-124-d14af685002f>\", line 3>\n        self.user_global_ns = {'C': [2, 1, 0.5, 0.1], 'In': ['', 'import numpy as np\\nimport pandas as pd', 'train_df = pd.read_csv(\"../data/train.csv\")\\ntest_df = pd.read_csv(\"../data/test.csv\")', 'train_df.head()', 'train_df.shape', 'test_df.shape', 'test_df.head()', 'train_df = pd.read_csv(\"../data/train.csv\", inde...= pd.read_csv(\"../data/test.csv\", index_col=\"ID\")', 'test_df.head()', 'train_df.head()', 'y = train_df[:]', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1. inplace=True)', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1, inplace=True)', 'train_df.head()', 'print(train_df.shape)\\ntrain_df.head()', 'y', 'y.nunique()', 'train_df[0]', 'train_df.values()[0]', 'train_df.values[0]', ...], 'Out': {3:           ID      target  48df886f9  0deb4b6a8  ...          0          0  \n\n[5 rows x 4993 columns], 4: (4459, 4993), 5: (49342, 4992), 6:           ID  48df886f9  0deb4b6a8  34b15f335  a...        0.0        0.0  \n\n[5 rows x 4992 columns], 8:            48df886f9  0deb4b6a8  34b15f335  a8cb...        0.0        0.0  \n\n[5 rows x 4991 columns], 9:                target  48df886f9  0deb4b6a8  34b...          0          0  \n\n[5 rows x 4992 columns], 13:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 14:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 15: ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, 16: 1413, ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, 'SVR': <class 'sklearn.svm.classes.SVR'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([12897.35154522, 14710.70136138, 11476.602...  9269.30800624, 11362.80565186,  7221.68147366]), '_100': array([[-0.03764565, -0.02163947, -0.04688961, .... -0.07234203,\n        -0.05636327, -0.12585201]]), '_102':            48df886f9  0deb4b6a8     34b15f335  a...f6f       0.000000  \n\n[49342 rows x 4991 columns], ...}\n        self.user_ns = {'C': [2, 1, 0.5, 0.1], 'In': ['', 'import numpy as np\\nimport pandas as pd', 'train_df = pd.read_csv(\"../data/train.csv\")\\ntest_df = pd.read_csv(\"../data/test.csv\")', 'train_df.head()', 'train_df.shape', 'test_df.shape', 'test_df.head()', 'train_df = pd.read_csv(\"../data/train.csv\", inde...= pd.read_csv(\"../data/test.csv\", index_col=\"ID\")', 'test_df.head()', 'train_df.head()', 'y = train_df[:]', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1. inplace=True)', 'y = train_df[\"target\"]\\ntrain_df.drop([\"target\"], axis=1, inplace=True)', 'train_df.head()', 'print(train_df.shape)\\ntrain_df.head()', 'y', 'y.nunique()', 'train_df[0]', 'train_df.values()[0]', 'train_df.values[0]', ...], 'Out': {3:           ID      target  48df886f9  0deb4b6a8  ...          0          0  \n\n[5 rows x 4993 columns], 4: (4459, 4993), 5: (49342, 4992), 6:           ID  48df886f9  0deb4b6a8  34b15f335  a...        0.0        0.0  \n\n[5 rows x 4992 columns], 8:            48df886f9  0deb4b6a8  34b15f335  a8cb...        0.0        0.0  \n\n[5 rows x 4991 columns], 9:                target  48df886f9  0deb4b6a8  34b...          0          0  \n\n[5 rows x 4992 columns], 13:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 14:            48df886f9  0deb4b6a8  34b15f335  a8cb...          0          0  \n\n[5 rows x 4991 columns], 15: ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, 16: 1413, ...}, 'PCA': <class 'sklearn.decomposition.pca.PCA'>, 'Ridge': <class 'sklearn.linear_model.ridge.Ridge'>, 'SVR': <class 'sklearn.svm.classes.SVR'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([12897.35154522, 14710.70136138, 11476.602...  9269.30800624, 11362.80565186,  7221.68147366]), '_100': array([[-0.03764565, -0.02163947, -0.04688961, .... -0.07234203,\n        -0.05636327, -0.12585201]]), '_102':            48df886f9  0deb4b6a8     34b15f335  a...f6f       0.000000  \n\n[49342 rows x 4991 columns], ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/santander/src/<ipython-input-124-d14af685002f> in <module>()\n      1 from sklearn.linear_model import Ridge\n      2 ridge = Ridge(random_state=17)\n----> 3 scores = cross_val_score(ridge, reduced_train, y, n_jobs = -1, verbose=1,  scoring=\"neg_mean_squared_log_error\")\n      4 print(np.mean(np.sqrt(-scores)))\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, groups=None, scoring='neg_mean_squared_log_error', cv=None, n_jobs=-1, verbose=1, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, groups=None, scoring={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, cv=KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=1, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-1.52457370e+07, -5.50024311e+05, -3.637...57591713e+06, -9.70560076e+05, -3.05371397e+06]])\n        y = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jun 23 18:26:59 2018\nPID: 5759Python 3.5.2: /home/snake/PycharmProjects/kaggle_competitions/.venv/bin/python3\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, array([1487, 1488, 1489, ..., 4456, 4457, 4458]), array([   0,    1,    2, ..., 1484, 1485, 1486]), 1, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...57591713e+06, -9.70560076e+05, -3.05371397e+06]]), y=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 4459, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, train=array([1487, 1488, 1489, ..., 4456, 4457, 4458]), test=array([   0,    1,    2, ..., 1484, 1485, 1486]), verbose=1, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorer={'score': make_scorer(mean_squared_log_error, greater_is_better=False)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n        scorer = {'score': make_scorer(mean_squared_log_error, greater_is_better=False)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/model_selection/_validation.py in _multimetric_score(estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X_test=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_test=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, scorers={'score': make_scorer(mean_squared_log_error, greater_is_better=False)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(mean_squared_log_error, greater_is_better=False)\n        estimator = Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001)\n        X_test = memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]])\n        y_test = ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/scorer.py in __call__(self=make_scorer(mean_squared_log_error, greater_is_better=False), estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True...False, random_state=17, solver='auto', tol=0.001), X=memmap([[-1.52457370e+07, -5.50024311e+05, -3.63...71946873e+06,  9.43111084e+05, -5.30945994e+05]]), y_true=ID\n000d6aaf2    38000000.00\n000fbd867      60000...000.00\nName: target, Length: 1487, dtype: float64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_log_error(y_true=array([[38000000.],\n       [  600000.],\n       [...00000.],\n       [ 6000000.],\n       [  922000.]]), y_pred=array([[  9008546.15738128],\n       [  6759237.4... 6826125.46616534],\n       [-25818253.49610107]]), sample_weight=None, multioutput='uniform_average')\n    310     if not (y_true >= 0).all() and not (y_pred >= 0).all():\n    311         raise ValueError(\"Mean Squared Logarithmic Error cannot be used when \"\n    312                          \"targets contain negative values.\")\n    313 \n    314     return mean_squared_error(np.log(y_true + 1), np.log(y_pred + 1),\n--> 315                               sample_weight, multioutput)\n        sample_weight = None\n        multioutput = 'uniform_average'\n    316 \n    317 \n    318 def median_absolute_error(y_true, y_pred):\n    319     \"\"\"Median absolute error regression loss\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in mean_squared_error(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), sample_weight=None, multioutput='uniform_average')\n    233     ... # doctest: +ELLIPSIS\n    234     0.824...\n    235 \n    236     \"\"\"\n    237     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 238         y_true, y_pred, multioutput)\n        y_true = array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]])\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n        multioutput = 'uniform_average'\n    239     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n    240                                weights=sample_weight)\n    241     if isinstance(multioutput, string_types):\n    242         if multioutput == 'raw_values':\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/metrics/regression.py in _check_reg_targets(y_true=array([[17.45309674],\n       [13.3046866 ],\n    ...18],\n       [15.60727019],\n       [13.73430159]]), y_pred=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), multioutput='uniform_average')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in check_array(array=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\n/home/snake/PycharmProjects/kaggle_competitions/.venv/lib/python3.5/site-packages/sklearn/utils/validation.py in _assert_all_finite(X=array([[16.01368437],\n       [15.72642079],\n    ...99],\n       [15.73626794],\n       [        nan]]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(random_state=17)\n",
    "scores = cross_val_score(ridge, reduced_train, y, n_jobs = -1, verbose=1,  scoring=\"neg_mean_squared_log_error\")\n",
    "print(np.mean(np.sqrt(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7576713977612872\n",
      "CPU times: user 192 ms, sys: 472 ms, total: 664 ms\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_clf = SVR(C=c, epsilon=e,cache_size=10000, verbose=True)\n",
    "scores = cross_val_score(svm_clf, reduced_train, y, n_jobs = -1, verbose=1,  scoring=\"neg_mean_squared_log_error\")\n",
    "print(np.mean(np.sqrt(-scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7576704987912395"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=10000, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_clf_pca = SVR(C=1.0, epsilon=0.2,cache_size=10000, verbose=True)\n",
    "svm_clf_pca.fit(reduced_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_preds = svm_clf_pca.predict(reduced_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]CPU times: user 2min 18s, sys: 216 ms, total: 2min 18s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVR\n",
    "svm_clf_final = SVR(C=1.0, epsilon=0.2,cache_size=10000, verbose=True)\n",
    "svm_clf_final.fit(train_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_preds = svm_clf_final.predict(test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = (svm_preds+pca_preds)/2.0\n",
    "def prepare_score_file(scores):\n",
    "    test_item_id = test_df.index\n",
    "    sub_df = pd.DataFrame({\"ID\":test_item_id})\n",
    "    sub_df[\"target\"] = scores\n",
    "    sub_df.to_csv(\"/tmp/santander.csv\", index=False)\n",
    "prepare_score_file(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
