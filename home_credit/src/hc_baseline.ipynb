{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_train.csv', 'POS_CASH_balance.csv', 'sample_submission.csv', 'bureau.csv', 'installments_payments.csv', 'bureau_balance.csv', 'previous_application.csv', 'application_test.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv']\n"
     ]
    }
   ],
   "source": [
    "# List files available\n",
    "print(os.listdir(\"../data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "              ...              FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...                             0                0   \n",
       "1             ...                             0                0   \n",
       "2             ...                             0                0   \n",
       "3             ...                             0                0   \n",
       "4             ...                             0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                0                0                        0.0   \n",
       "1                0                0                        0.0   \n",
       "2                0                0                        0.0   \n",
       "3                0                0                        NaN   \n",
       "4                0                0                        0.0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       0.0                         0.0   \n",
       "2                       0.0                         0.0   \n",
       "3                       NaN                         NaN   \n",
       "4                       0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         NaN  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv('../data/application_train.csv')\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape:  (48744, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "              ...             FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...                            0                0   \n",
       "1             ...                            0                0   \n",
       "2             ...                            0                0   \n",
       "3             ...                            0                0   \n",
       "4             ...                            0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                0                0                        0.0   \n",
       "1                0                0                        0.0   \n",
       "2                0                0                        0.0   \n",
       "3                0                0                        0.0   \n",
       "4                0                0                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        0.0                         0.0   \n",
       "4                        NaN                         NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        1.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         0.0  \n",
       "1                         3.0  \n",
       "2                         4.0  \n",
       "3                         3.0  \n",
       "4                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing data features\n",
    "app_test = pd.read_csv('../data/application_test.csv')\n",
    "print('Testing data shape: ', app_test.shape)\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 122 columns.\n",
      "There are 67 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>210295</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <td>202929</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Missing Values  % of Total Values\n",
       "COMMONAREA_MEDI                   214865               69.9\n",
       "COMMONAREA_AVG                    214865               69.9\n",
       "COMMONAREA_MODE                   214865               69.9\n",
       "NONLIVINGAPARTMENTS_MEDI          213514               69.4\n",
       "NONLIVINGAPARTMENTS_MODE          213514               69.4\n",
       "NONLIVINGAPARTMENTS_AVG           213514               69.4\n",
       "FONDKAPREMONT_MODE                210295               68.4\n",
       "LIVINGAPARTMENTS_MODE             210199               68.4\n",
       "LIVINGAPARTMENTS_MEDI             210199               68.4\n",
       "LIVINGAPARTMENTS_AVG              210199               68.4\n",
       "FLOORSMIN_MODE                    208642               67.8\n",
       "FLOORSMIN_MEDI                    208642               67.8\n",
       "FLOORSMIN_AVG                     208642               67.8\n",
       "YEARS_BUILD_MODE                  204488               66.5\n",
       "YEARS_BUILD_MEDI                  204488               66.5\n",
       "YEARS_BUILD_AVG                   204488               66.5\n",
       "OWN_CAR_AGE                       202929               66.0\n",
       "LANDAREA_AVG                      182590               59.4\n",
       "LANDAREA_MEDI                     182590               59.4\n",
       "LANDAREA_MODE                     182590               59.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "missing_values = missing_values_table(app_train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    65\n",
       "int64      41\n",
       "object     16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 243)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "app_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\n",
    "plt.xlabel('Days Employment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9274 anomalies in the test data out of 48744 entries\n"
     ]
    }
   ],
   "source": [
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "print('There are %d anomalies in the test data out of %d entries' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe for polynomial features\n",
    "poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
    "poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "\n",
    "# imputer for handling missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "poly_target = poly_features['TARGET']\n",
    "\n",
    "poly_features = poly_features.drop(columns = ['TARGET'])\n",
    "\n",
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "                                  \n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features shape:  (307511, 35)\n"
     ]
    }
   ],
   "source": [
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT_SOURCE_2 EXT_SOURCE_3                -0.193939\n",
      "EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   -0.189605\n",
      "EXT_SOURCE_2^2 EXT_SOURCE_3              -0.176428\n",
      "EXT_SOURCE_2 EXT_SOURCE_3^2              -0.172282\n",
      "EXT_SOURCE_1 EXT_SOURCE_2                -0.166625\n",
      "EXT_SOURCE_1 EXT_SOURCE_3                -0.164065\n",
      "EXT_SOURCE_2                             -0.160295\n",
      "EXT_SOURCE_1 EXT_SOURCE_2^2              -0.156867\n",
      "EXT_SOURCE_3                             -0.155892\n",
      "EXT_SOURCE_1 EXT_SOURCE_3^2              -0.150822\n",
      "Name: TARGET, dtype: float64\n",
      "EXT_SOURCE_1 EXT_SOURCE_2 DAYS_BIRTH    0.155891\n",
      "EXT_SOURCE_2 DAYS_BIRTH                 0.156873\n",
      "EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH    0.181283\n",
      "TARGET                                  1.000000\n",
      "1                                            NaN\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the features \n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Add in the target\n",
    "poly_features['TARGET'] = poly_target\n",
    "\n",
    "# Find the correlations with the target\n",
    "poly_corrs = poly_features.corr()['TARGET'].sort_values()\n",
    "\n",
    "# Display most negative and most positive\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data with polynomial features shape:  (307511, 275)\n",
      "Testing data with polynomial features shape:   (48744, 275)\n"
     ]
    }
   ],
   "source": [
    "# Put test features into dataframe\n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Merge polynomial features into training dataframe\n",
    "poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\n",
    "app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge polnomial features into testing dataframe\n",
    "poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
    "app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Align the dataframes\n",
    "app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n",
    "\n",
    "# Print out the new shapes\n",
    "print('Training data with polynomial features shape: ', app_train_poly.shape)\n",
    "print('Testing data with polynomial features shape:  ', app_test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']\n",
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 240)\n",
      "Testing data shape:  (48744, 240)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "# Drop the target from the training data\n",
    "if 'TARGET' in app_train:\n",
    "    train = app_train.drop(columns = ['TARGET'])\n",
    "else:\n",
    "    train = app_train.copy()\n",
    "    \n",
    "# Feature names\n",
    "features = list(train.columns)\n",
    "\n",
    "# Copy of the testing data\n",
    "test = app_test.copy()\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "# Scale each feature to 0-1\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "imputer.fit(train)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train = imputer.transform(train)\n",
    "test = imputer.transform(app_test)\n",
    "\n",
    "# Repeat with the scaler\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Testing data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Make the model with the specified regularization parameter\n",
    "log_reg = LogisticRegression(C = 0.0001)\n",
    "\n",
    "# Train on the training data\n",
    "log_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to select the second column only\n",
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.066677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.128855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.084450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.060502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.127878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.066677\n",
       "1      100005  0.128855\n",
       "2      100013  0.084450\n",
       "3      100028  0.060502\n",
       "4      100038  0.127878"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submission dataframe\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = log_reg_pred\n",
    "\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the submission to a csv file\n",
    "submit.to_csv('/tmp/log_reg_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Make the random forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   54.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Train on the training data\n",
    "random_forest.fit(train, train_labels)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance_values = random_forest.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = random_forest.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission dataframe\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "\n",
    "# Save the submission dataframe\n",
    "submit.to_csv('/tmp/random_forest_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features_names = list(app_train_poly.columns)\n",
    "\n",
    "# Impute the polynomial features\n",
    "imputer = Imputer(strategy = 'median')\n",
    "\n",
    "poly_features = imputer.fit_transform(app_train_poly)\n",
    "poly_features_test = imputer.transform(app_test_poly)\n",
    "\n",
    "# Scale the polynomial features\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "poly_features = scaler.fit_transform(poly_features)\n",
    "poly_features_test = scaler.transform(poly_features_test)\n",
    "\n",
    "random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Train on the training data\n",
    "random_forest_poly.fit(poly_features, train_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission dataframe\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "\n",
    "# Save the submission dataframe\n",
    "submit.to_csv('/tmp/random_forest_baseline_engineered.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "def model(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 239)\n",
      "Testing Data Shape:  (48744, 239)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.755302\ttrain's auc: 0.798776\n",
      "[400]\tvalid's auc: 0.755183\ttrain's auc: 0.828115\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid's auc: 0.755926\ttrain's auc: 0.818572\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.758343\ttrain's auc: 0.798672\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid's auc: 0.758486\ttrain's auc: 0.812801\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.763014\ttrain's auc: 0.797711\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid's auc: 0.763203\ttrain's auc: 0.809099\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.75847\ttrain's auc: 0.798878\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid's auc: 0.758583\ttrain's auc: 0.80545\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.757646\ttrain's auc: 0.798121\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid's auc: 0.75805\ttrain's auc: 0.809058\n",
      "Baseline metrics\n",
      "      fold     train     valid\n",
      "0        0  0.818572  0.755926\n",
      "1        1  0.812801  0.758486\n",
      "2        2  0.809099  0.763203\n",
      "3        3  0.805450  0.758583\n",
      "4        4  0.809058  0.758050\n",
      "5  overall  0.810996  0.758842\n"
     ]
    }
   ],
   "source": [
    "submission, fi, metrics = model(app_train, app_test)\n",
    "print('Baseline metrics')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (307511, 243)\n",
      "Testing Data Shape:  (48744, 243)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.762338\ttrain's auc: 0.804314\n",
      "[400]\tvalid's auc: 0.762761\ttrain's auc: 0.834152\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid's auc: 0.763049\ttrain's auc: 0.822054\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.765734\ttrain's auc: 0.804122\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid's auc: 0.765997\ttrain's auc: 0.811303\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.769296\ttrain's auc: 0.803449\n",
      "[400]\tvalid's auc: 0.769715\ttrain's auc: 0.834016\n",
      "Early stopping, best iteration is:\n",
      "[377]\tvalid's auc: 0.769914\ttrain's auc: 0.830819\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.764789\ttrain's auc: 0.804237\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid's auc: 0.764961\ttrain's auc: 0.80949\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.764833\ttrain's auc: 0.804494\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid's auc: 0.765275\ttrain's auc: 0.820087\n",
      "Baseline with domain knowledge features metrics\n",
      "      fold     train     valid\n",
      "0        0  0.822054  0.763049\n",
      "1        1  0.811303  0.765997\n",
      "2        2  0.830819  0.769914\n",
      "3        3  0.809490  0.764961\n",
      "4        4  0.820087  0.765275\n",
      "5  overall  0.818751  0.765838\n"
     ]
    }
   ],
   "source": [
    "app_train_domain['TARGET'] = train_labels\n",
    "\n",
    "# Test the domain knolwedge features\n",
    "submission_domain, fi_domain, metrics_domain = model(app_train_domain, app_test_domain)\n",
    "print('Baseline with domain knowledge features metrics')\n",
    "print(metrics_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_domain.to_csv('/tmp/final_baseline_lgb_domain_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
